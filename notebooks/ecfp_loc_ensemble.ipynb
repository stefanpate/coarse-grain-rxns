{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cgr.filepaths import filepaths\n",
    "from cgr.draw import draw_molecule, draw_reaction\n",
    "from cgr.cheminfo import MorganFingerprinter, extract_subgraph\n",
    "import json\n",
    "from IPython.display import SVG\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from scipy.stats import entropy\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_leaves(embeds, leaf, translator=None):\n",
    "    asked, answered = zip(*[elt for elt in chain(*leaf)])\n",
    "\n",
    "    if translator:\n",
    "        asked = translator[asked]\n",
    "\n",
    "    reaction_mask = []\n",
    "    for q, a in zip(asked, answered):\n",
    "        reaction_mask.append(embeds[:, q] == a)\n",
    "    \n",
    "    reaction_idxs = np.argwhere(np.prod(np.vstack(reaction_mask), axis=0).astype(int))\n",
    "\n",
    "    return reaction_idxs.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "krs = filepaths.data / \"raw\" / \"sprhea_240310_v3_mapped_no_subunits.json\"\n",
    "with open(krs, 'r') as f:\n",
    "    krs = json.load(f)\n",
    "\n",
    "decarb = {k: v for k,v  in krs.items() if v['min_rule'] == 'rule0024'}\n",
    "print(len(decarb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_hops = 3\n",
    "vec_len = 2**12\n",
    "mfper = MorganFingerprinter(radius=max_hops, length=vec_len, allocate_ao=True)\n",
    "rc_dist_ub = None\n",
    "n_samples = len(decarb)\n",
    "\n",
    "full_embeds = []\n",
    "subgraph_cts = defaultdict(lambda : defaultdict(int)) # {bit_idx: {(rid, central_aidx, radius): count}}\n",
    "bit_examples = defaultdict(list) # {bit_idx: dict(mol, rid, central_aidx, radius)}\n",
    "row2rid = list(decarb.keys())\n",
    "for rid, rxn in decarb.items():\n",
    "        rc = rxn['reaction_center'][0]\n",
    "        smiles = rxn['smarts'].split('>>')[0]\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "        full_embeds.append(mfper.fingerprint(mol, reaction_center=rc, rc_dist_ub=rc_dist_ub))\n",
    "        bim = mfper.bit_info_map\n",
    "\n",
    "\n",
    "        for bit_idx, examples in bim.items():\n",
    "            for (central_aidx, radius) in examples:\n",
    "                bit_examples[bit_idx].append(\n",
    "                    {\n",
    "                        'mol': mol,\n",
    "                        'rid': rid,\n",
    "                        'central_aidx': central_aidx,\n",
    "                        'radius': radius\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                sub_idxs, sub_mol, sub_smi = extract_subgraph(mol, central_aidx, radius)\n",
    "\n",
    "                subgraph_cts[bit_idx][(sub_smi, radius)] += 1\n",
    "\n",
    "full_embeds = np.vstack(full_embeds)\n",
    "\n",
    "r2bits = defaultdict(list) # {radius: [bit idxs]}\n",
    "for bit_idx, examples in subgraph_cts.items():\n",
    "    r_max = sorted(examples.items(), key= lambda x : x[1], reverse=True)[0][0][1] # Sort by frequency over rxns\n",
    "    r2bits[r_max].append(bit_idx)\n",
    "\n",
    "# Add in only the most common. This is wrong?\n",
    "embed_stack = np.zeros(shape=(n_samples, vec_len, max_hops + 1))\n",
    "for r, bits in r2bits.items():\n",
    "    embed_stack[:, bits, r] = full_embeds[:, bits]\n",
    "\n",
    "p1 = embed_stack.sum(axis=0) / n_samples\n",
    "p1 = p1[np.newaxis, :]\n",
    "probas = np.vstack((p1, (1 - p1)))\n",
    "H = entropy(pk=probas, axis=0, base=2)\n",
    "p1 = p1.squeeze()\n",
    "\n",
    "# Filter out non-majority examples\n",
    "tmp = {}\n",
    "for r, idxs in r2bits.items():\n",
    "     for idx in idxs:\n",
    "          tmp[idx] = [elt for elt in bit_examples[idx] if elt['radius'] == r]\n",
    "\n",
    "bit_examples = tmp\n",
    "\n",
    "resolved_embeds = embed_stack.sum(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale-separated loc ecfp embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rng = np.random.default_rng(seed=1234) # TODO seed=1234, resampling same integer for first hash / substruct\n",
    "n_egs = 1\n",
    "topk = 100\n",
    "khop = 1 # Scale desired - how many hops from central atom\n",
    "sort_by = p1\n",
    "\n",
    "srt_idx = np.argsort(sort_by[:, khop])[::-1]\n",
    "\n",
    "for idx in srt_idx[:topk]:\n",
    "    egs = bit_examples[idx][:n_egs]\n",
    "    print(f\"Bit idx: {idx}\")\n",
    "    print(f\"Entropy = {H[idx, khop]} bits\")\n",
    "    print(f\"Probability: {p1[idx, khop]:.2f}\")\n",
    "    for eg in egs:\n",
    "        mol = eg['mol']\n",
    "        aidx = eg['central_aidx']\n",
    "        r = eg['radius']\n",
    "\n",
    "        sub_idxs, sub_mol, sub_smi = extract_subgraph(mol, aidx, r)\n",
    "\n",
    "        display(SVG(draw_molecule(mol, size=(300, 300), hilite_atoms=tuple(sub_idxs))))\n",
    "    \n",
    "    print('-' * 50)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_proba_mass = resolved_embeds.sum(axis=0) / n_samples\n",
    "nonzero_features = np.where((ft_proba_mass > 0) * (ft_proba_mass < 1))[0]\n",
    "nonzero_embeds = resolved_embeds[:, nonzero_features]\n",
    "\n",
    "resolved_p1 = nonzero_embeds.sum(axis=0) / n_samples\n",
    "resolved_probas = np.vstack((resolved_p1, (1 - resolved_p1)))\n",
    "resolved_H = entropy(pk=resolved_probas, axis=0, base=2)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(1, nonzero_embeds.shape[1] + 1), sorted(resolved_p1, reverse=True))\n",
    "ax.set_ylabel(\"P(feature = 1)\")\n",
    "ax.set_xlabel(\"Feature rank\")\n",
    "ax.hlines(1 / n_samples, xmin=1, xmax=nonzero_embeds.shape[1], color='black', linestyles='--', label=\"1 / # samples\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scl = 5\n",
    "(resolved_p1 <= (scl / n_samples)).sum() / resolved_p1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster structural features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_embeds(embeds: np.ndarray, asked: list, not_asked: list, answered: list):\n",
    "    reaction_mask = []\n",
    "    for q, a in zip(asked, answered):\n",
    "        reaction_mask.append(embeds[:, q] == a)\n",
    "    \n",
    "    if reaction_mask:\n",
    "        reaction_mask = np.prod(np.vstack(reaction_mask), axis=0).astype(bool)\n",
    "        remaining_embeds = embeds[reaction_mask, :][:, not_asked]\n",
    "    else:\n",
    "        remaining_embeds = embeds[:, not_asked]\n",
    "\n",
    "    return remaining_embeds\n",
    "\n",
    "def find_feature_clusters(embeds: np.ndarray, scl_lb:int = 1, leaves: list = []):\n",
    "    def bts(qna: list[tuple[tuple]] = []):\n",
    "        if qna:\n",
    "            asked, answered = zip(*[elt for elt in chain(*qna)])\n",
    "        else:\n",
    "            asked, answered = [], []\n",
    "\n",
    "        not_asked = np.array([i for i in range(embeds.shape[1]) if i not in asked]).astype(int)\n",
    "\n",
    "        remaining_embeds = prune_embeds(embeds, asked, not_asked, answered)\n",
    "\n",
    "        if remaining_embeds.shape[0] < 2:\n",
    "            return qna\n",
    "\n",
    "        n_remaining_rxns = remaining_embeds.shape[0]\n",
    "        remaining_p1 = remaining_embeds.sum(axis=0) / n_remaining_rxns\n",
    "        next_question = np.argmax(remaining_p1)\n",
    "\n",
    "        if remaining_p1[next_question] <= (scl_lb / n_remaining_rxns):\n",
    "            return qna\n",
    "\n",
    "        next_distribution = remaining_embeds[:, next_question] # n_samples, \n",
    "        dots = remaining_embeds.T @ next_distribution.reshape(-1, 1) # n_remaingin_fts x 1\n",
    "        jaccards = (dots / (next_distribution.sum() + remaining_embeds.T.sum(axis=1).reshape(-1, 1) - dots)).reshape(-1,)\n",
    "        next_question = np.where(jaccards == 1)[0] # Get completely redundant features\n",
    "        next_question = [int(elt) for elt in not_asked[next_question]] # Translate to indices of full feature space\n",
    "\n",
    "        for ans in range(2):\n",
    "            next_qna = tuple(zip(next_question, [ans for _ in range(len(next_question))]))\n",
    "            leaves.append(\n",
    "                bts(qna=qna + [next_qna])\n",
    "            )\n",
    "    \n",
    "    bts()\n",
    "    leaves = [l for l in leaves if l is not None]\n",
    "\n",
    "    return leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeds = np.array(\n",
    "    [\n",
    "        [1, 1, 1],\n",
    "        [1, 0, 0],\n",
    "        [0, 0, 0]\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_leaves = []\n",
    "find_feature_clusters(test_embeds, leaves=test_leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_leaves = []\n",
    "nonzero_leaves = find_feature_clusters(nonzero_embeds, scl_lb=5, leaves=nonzero_leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([l for l in nonzero_leaves if l is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_levels = []\n",
    "n_rxns = []\n",
    "for leaf in nonzero_leaves:\n",
    "    n_levels.append(len(leaf))\n",
    "    n_rxns.append(len(pick_leaves(nonzero_embeds, leaf)))\n",
    "\n",
    "print(n_levels)\n",
    "print(n_rxns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "n_egs = 1\n",
    "leaves = nonzero_leaves\n",
    "\n",
    "leaf = leaves[i]\n",
    "\n",
    "print([elt[0][1] for elt in leaf])\n",
    "for redundant_group in leaf:\n",
    "    q, a = redundant_group[0]\n",
    "    idx = nonzero_features[q] # Translate\n",
    "    egs = bit_examples[idx][:n_egs]\n",
    "    print(f\"Bit idx: {idx}. Present? {a}\")\n",
    "    print(f\"Entropy = {resolved_H[q]} bits\")\n",
    "    print(f\"Probability: {resolved_p1[q]:.2f}\")\n",
    "    for eg in egs:\n",
    "        mol = eg['mol']\n",
    "        aidx = eg['central_aidx']\n",
    "        r = eg['radius']\n",
    "\n",
    "        sub_idxs, sub_mol, sub_smi = extract_subgraph(mol, aidx, r)\n",
    "\n",
    "        display(SVG(draw_molecule(mol, size=(300, 300), hilite_atoms=tuple(sub_idxs))))\n",
    "        \n",
    "    print('-' * 50)\n",
    "\n",
    "reaction_rows = pick_leaves(nonzero_embeds, leaf)\n",
    "print(f\"# cluster reactions: {len(reaction_rows)}\")\n",
    "for row in reaction_rows:\n",
    "    rxn = decarb[row2rid[row]]\n",
    "    print(rxn['imt_rules'])\n",
    "    print(rxn['rhea_ids'])\n",
    "    smiles = rxn['smarts'].split('>>')[0]\n",
    "    rc = rxn['reaction_center'][0]\n",
    "    display(SVG(draw_molecule(smiles, hilite_atoms=rc, size=(300, 300))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for leaf in nonzero_leaves:\n",
    "    reaction_rows = pick_leaves(nonzero_embeds, leaf)\n",
    "    print(f\"# levels: {len(leaf)}\")\n",
    "    print(f\"# cluster reactions: {len(reaction_rows)}\")\n",
    "    for row in reaction_rows:\n",
    "        rxn = decarb[row2rid[row]]\n",
    "        print(rxn['imt_rules'])\n",
    "        print(rxn['rhea_ids'])\n",
    "        smiles = rxn['smarts'].split('>>')[0]\n",
    "        rc = rxn['reaction_center'][0]\n",
    "        display(SVG(draw_molecule(smiles, hilite_atoms=rc, size=(300, 300))))\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation & anti-correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = full_embeds # embed_stack[:, :, 0]\n",
    "\n",
    "ft_proba_mass = embeds.sum(axis=0) / n_samples\n",
    "nonzero_features = np.where((ft_proba_mass > 0) * (ft_proba_mass < 1))[0]\n",
    "nonzero_embeds = embeds[:, nonzero_features]\n",
    "directed_embeds = (nonzero_embeds - 0.5) * 2\n",
    "hamming_corr = np.matmul(directed_embeds.T, directed_embeds) / directed_embeds.shape[0]\n",
    "triu_idxs = np.triu_indices_from(hamming_corr, k=1)\n",
    "hamming_corr_upper = hamming_corr[triu_idxs]\n",
    "feature_pairs = list(zip(*triu_idxs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_triple = np.zeros(shape=(nonzero_embeds.shape[1], nonzero_embeds.shape[1], 3))\n",
    "for i in range(nonzero_embeds.shape[1] - 1):\n",
    "    for j in range(i + 1, nonzero_embeds.shape[1]):\n",
    "        raw_weights = Counter(nonzero_embeds[:, (i, j)].sum(axis=1))\n",
    "        idxs, counts = zip(*raw_weights.items())\n",
    "        counts = [ct / n_samples for ct in counts]\n",
    "        interaction_triple[i, j, idxs] = counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cgr-ltW6jZuu-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
