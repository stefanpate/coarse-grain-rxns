{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41c9c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11195b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "from hydra import initialize, compose\n",
    "from rdkit import Chem\n",
    "from collections import defaultdict\n",
    "from ergochemics.mapping import rc_to_nest\n",
    "from ergochemics.draw import draw_reaction, draw_molecule\n",
    "from IPython.display import SVG\n",
    "from cgr.ml import bin_label_to_sep_aidx\n",
    "import yaml\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "from ergochemics.mapping import (\n",
    "    get_reaction_center\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    "    RocCurveDisplay,\n",
    "    PrecisionRecallDisplay,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "\n",
    "with initialize(version_base=None, config_path=\"../configs/filepaths\"):\n",
    "    cfg = compose(config_name=\"filepaths\")\n",
    "\n",
    "mlflow.set_tracking_uri(f\"file://{cfg.mlruns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5eaab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_min_dist_to_rc(am_rxn: str, rc: list[list[list[int]], list[list[int]]]) -> list[list[list[int]], list[list[int]]]:\n",
    "    mols = [[Chem.MolFromSmiles(elt) for elt in side.split('.')] for side in am_rxn.split('>>')]\n",
    "    min_dists = [[], []]\n",
    "    for i, side_rc in enumerate(rc):\n",
    "        for mol, rc in zip(mols[i], side_rc):\n",
    "            for atom in mol.GetAtoms():\n",
    "                aidx = atom.GetIdx()\n",
    "                min_dist = min(len(Chem.GetShortestPath(mol, aidx, rcidx)) - 1 if aidx != rcidx else 0 for rcidx in rc)\n",
    "\n",
    "                min_dists[i].append(min_dist)\n",
    "    return [np.array(elt).reshape(-1, 1) for elt in min_dists]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12014b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"production\"\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "if experiment:\n",
    "    df = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "else:\n",
    "    print(f\"Experiment '{experiment_name}' not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d33b05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc83a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy configs to conf dir to train production model\n",
    "for i, row in df.iterrows():\n",
    "    fn = f\"outer_split_{row['params.data/outer_split_idx']}.yaml\"\n",
    "    out_path = Path(cfg.configs) / \"production\" / fn\n",
    "    artifact_dir = Path(row['artifact_uri'].replace(\"file:///home/stef/cgr\", \"/home/stef/cgr\"))\n",
    "    model_ckpt_abs = next(artifact_dir.rglob(\"*.ckpt\"))\n",
    "    model_ckpt_rel = model_ckpt_abs.relative_to(cfg.mlruns)\n",
    "    print(\"checkpoint: \", model_ckpt_rel)\n",
    "\n",
    "    config = defaultdict(dict)\n",
    "    for k, v in row.items():\n",
    "        if k.startswith(\"params.\") and \"/\" in k:\n",
    "            k_out, k_in, *_ = k.removeprefix(\"params.\").split(\"/\")\n",
    "\n",
    "            if k_out == \"full\":\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                config[k_out][k_in] = literal_eval(v)\n",
    "            except ValueError:\n",
    "                config[k_out][k_in] = v\n",
    "    \n",
    "    config[\"model\"][\"ckpt\"] = str(model_ckpt_rel)\n",
    "\n",
    "    with open(out_path, \"w\") as f:\n",
    "        yaml.dump(dict(config), f)\n",
    "    \n",
    "    print(f\"Saving config to: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa9ee48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4d7381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = []\n",
    "# for fn in (Path(cfg.processed_data) / \"mech_probas\").glob(\"*.parquet\"):\n",
    "#     print(\"Loading: \", fn)\n",
    "#     preds.append(pd.read_parquet(fn))\n",
    "\n",
    "# dts = [0.9562190771102905, 0.05624692514538765, 0.01461805310100317, 0.0060590095818042755, 0.0028916343580931425]\n",
    "# pred_df = pd.concat(preds)\n",
    "# avg = pred_df.groupby([\"rxn_id\", \"aidx\"])[\"probas\"].mean().reset_index()\n",
    "# pop_vote = []\n",
    "# avg_model = []\n",
    "# for dt in tqdm(dts, total=len(dts)):\n",
    "#     pred_df['label'] = (pred_df['probas'] > dt).astype(int)\n",
    "#     grouped = pred_df.groupby(['rxn_id', 'aidx'])['label'].agg(lambda x: x.mode()[0]).reset_index()\n",
    "#     pop_vote.append(grouped)\n",
    "#     avg_model.append((avg['probas'] > dt).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a931faff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_truth = pred_df.drop_duplicates(subset=[\"rxn_id\", \"aidx\"], keep=\"first\").reset_index(drop=True)\n",
    "# for dt, pop_ans, avg_ans in zip(dts, pop_vote, avg_model):\n",
    "#     y = ground_truth['label']\n",
    "#     pop_y_pred = pop_ans['label']\n",
    "#     avg_y_pred = avg_ans\n",
    "\n",
    "#     f1_pop = f1_score(y, pop_y_pred)\n",
    "#     f1_avg = f1_score(y, avg_y_pred)\n",
    "#     acc_pop = accuracy_score(y, pop_y_pred)\n",
    "#     acc_avg = accuracy_score(y, avg_y_pred)\n",
    "\n",
    "#     print(f\"Decision threshold: {dt:.5f}\")\n",
    "#     print(f\"  Popularity vote - F1: {f1_pop:.4f}, Acc: {acc_pop:.4f}\")\n",
    "#     print(f\"  Average model   - F1: {f1_avg:.4f}, Acc: {acc_avg:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cgr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
